{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London House Price Predictive Model\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt, timezone as tz\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kaggle_london_house_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                                   object\n",
       "postcode                                      object\n",
       "country                                       object\n",
       "outcode                                       object\n",
       "latitude                                     float64\n",
       "longitude                                    float64\n",
       "bathrooms                                    float64\n",
       "bedrooms                                     float64\n",
       "floorAreaSqM                                 float64\n",
       "livingRooms                                  float64\n",
       "tenure                                        object\n",
       "propertyType                                  object\n",
       "currentEnergyRating                           object\n",
       "rentEstimate_lowerPrice                      float64\n",
       "rentEstimate_currentPrice                    float64\n",
       "rentEstimate_upperPrice                      float64\n",
       "saleEstimate_lowerPrice                      float64\n",
       "saleEstimate_currentPrice                    float64\n",
       "saleEstimate_upperPrice                      float64\n",
       "saleEstimate_confidenceLevel                  object\n",
       "saleEstimate_ingestedAt                       object\n",
       "saleEstimate_valueChange.numericChange       float64\n",
       "saleEstimate_valueChange.percentageChange    float64\n",
       "saleEstimate_valueChange.saleDate             object\n",
       "history_date                                  object\n",
       "history_price                                  int64\n",
       "history_percentageChange                     float64\n",
       "history_numericChange                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_date'] = pd.to_datetime(df['saleEstimate_ingestedAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_df = df.drop(columns=['history_numericChange', 'history_percentageChange', 'history_date', 'history_price','saleEstimate_valueChange.saleDate','saleEstimate_valueChange.percentageChange','saleEstimate_ingestedAt','saleEstimate_valueChange.numericChange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = key_df[key_df['sale_date'] > dt(2015, 1,1).replace(tzinfo=tz.utc)] #Only considering houses with estimated values in the last 10 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                         0\n",
       "postcode                            0\n",
       "country                             0\n",
       "outcode                             0\n",
       "latitude                            0\n",
       "longitude                           0\n",
       "bathrooms                       77755\n",
       "bedrooms                        40404\n",
       "floorAreaSqM                    25066\n",
       "livingRooms                     60341\n",
       "tenure                          11494\n",
       "propertyType                     1126\n",
       "currentEnergyRating             84288\n",
       "rentEstimate_lowerPrice          1101\n",
       "rentEstimate_currentPrice        1101\n",
       "rentEstimate_upperPrice          1101\n",
       "saleEstimate_lowerPrice             0\n",
       "saleEstimate_currentPrice           0\n",
       "saleEstimate_upperPrice             0\n",
       "saleEstimate_confidenceLevel        0\n",
       "sale_date                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                         0\n",
       "postcode                            0\n",
       "country                             0\n",
       "outcode                             0\n",
       "latitude                            0\n",
       "longitude                           0\n",
       "bathrooms                           0\n",
       "bedrooms                            0\n",
       "floorAreaSqM                        0\n",
       "livingRooms                         0\n",
       "tenure                           1702\n",
       "propertyType                        0\n",
       "currentEnergyRating             51266\n",
       "rentEstimate_lowerPrice            16\n",
       "rentEstimate_currentPrice          16\n",
       "rentEstimate_upperPrice            16\n",
       "saleEstimate_lowerPrice             0\n",
       "saleEstimate_currentPrice           0\n",
       "saleEstimate_upperPrice             0\n",
       "saleEstimate_confidenceLevel        0\n",
       "sale_date                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = house_df.dropna(subset=['bathrooms', 'livingRooms','bedrooms','floorAreaSqM'])\n",
    "temp_df.isna().sum() # Cannot impute the number of rooms and area of a building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "Leasehold    178804\n",
       "Feudal         2796\n",
       "Freehold       2039\n",
       "Shared          451\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_df = temp_df[temp_df['propertyType'].str.lower().str.contains('flat')]\n",
    "flat_df['tenure'].value_counts() # 98% of flats are leasehold. Would be therefore valid to impute that any flats w/o tenure are in fact leasehold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currentEnergyRating\n",
       "C    69632\n",
       "D    49279\n",
       "B    22602\n",
       "E     9409\n",
       "F      586\n",
       "A      105\n",
       "G      101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_df['currentEnergyRating'].value_counts() #Normally distributed around C/D could impute with preference for B,C,D,E for flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_flat_df = temp_df[~temp_df['propertyType'].str.lower().str.contains('flat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "Freehold     128580\n",
       "Leasehold      4128\n",
       "Feudal           56\n",
       "Shared           22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_flat_df['tenure'].value_counts() #Houses tend to be freehold with 97% of houses Freehold, impute freehold for non flat properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currentEnergyRating\n",
       "D    64439\n",
       "C    32420\n",
       "E    15526\n",
       "B     1714\n",
       "F     1061\n",
       "G      329\n",
       "A      109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_flat_df['currentEnergyRating'].value_counts() #Sharper normal distribution centered around D, could impute with preference for C,D,E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exploration of the data has clear reasoning for imputing some fields and removing rows with missing key fields.\n",
    "- Bathrooms : Cannot be reliably imputed and is necessary for the future model\n",
    "- Living Rooms: Cannot be reliably imputed and is necessary for the future model\n",
    "- Floor Area : Cannot be reliably imputed and is necessary for the future model\n",
    "- Tenure: Can be reliably imputed and is necessary for the future model\n",
    "- Energy rating: Can be reliably imputed and is necessary for the future model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "\n",
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex.Barnes\\AppData\\Local\\Temp\\ipykernel_29524\\2432086349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_df.drop(columns=['rentEstimate_lowerPrice', 'rentEstimate_currentPrice', 'rentEstimate_upperPrice', 'sale_date','saleEstimate_confidenceLevel'],inplace=True)\n",
      "C:\\Users\\Alex.Barnes\\AppData\\Local\\Temp\\ipykernel_29524\\2432086349.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_df['tenure'] = sales_df['propertyType'].apply(lambda x: 'Leasehold' if 'flat' in x.lower() else 'Freehold')\n"
     ]
    }
   ],
   "source": [
    "sales_df = house_df.dropna(subset=['bathrooms', 'livingRooms', 'bedrooms', 'floorAreaSqM']) \n",
    "sales_df.drop(columns=['rentEstimate_lowerPrice', 'rentEstimate_currentPrice', 'rentEstimate_upperPrice', 'sale_date','saleEstimate_confidenceLevel'],inplace=True)\n",
    "sales_df['tenure'] = sales_df['propertyType'].apply(lambda x: 'Leasehold' if 'flat' in x.lower() else 'Freehold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullAddress', 'postcode', 'country', 'outcode', 'latitude',\n",
       "       'longitude', 'bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms',\n",
       "       'tenure', 'propertyType', 'currentEnergyRating',\n",
       "       'saleEstimate_lowerPrice', 'saleEstimate_currentPrice',\n",
       "       'saleEstimate_upperPrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flats = sales_df[sales_df['propertyType'].str.lower().str.contains('flat')]\n",
    "houses = sales_df[~sales_df['propertyType'].str.lower().str.contains('flat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in [flats, houses]:\n",
    "    mean_rating = group['currentEnergyRating'].dropna().astype(str).mode()[0]\n",
    "    std_dev = 1\n",
    "    missing_idx = group['currentEnergyRating'].isna()\n",
    "    group.loc[missing_idx, 'currentEnergyRating'] = np.random.choice(\n",
    "        [mean_rating], size=missing_idx.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([flats, houses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms']\n",
    "categorical_features = ['tenure', 'propertyType', 'currentEnergyRating']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numerical_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "        \"Ridge\": {\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        'model__C': [1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [10, 20],\n",
    "        'model__max_features': ['sqrt', 'log2'],\n",
    "        'model__min_samples_split': [5, 10],\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        'model__n_estimators': [100, 300],\n",
    "        'model__learning_rate': [0.05, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/house_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/house_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[categorical_features+numerical_features], df['saleEstimate_currentPrice'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name,model,param_grids,preprocessor,best_models):\n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=10,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=5,\n",
    "        n_jobs=10\n",
    "    )\n",
    "    grid_search.fit(X_train.iloc[:10000], y_train.iloc[:10000])\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for name,model in models.items():\n",
    "    best_models = train_model(name,model,param_grids,preprocessor,best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"model_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "def train_model_presets(name, model, preprocessor, best_models):\n",
    "    cache_path = os.path.join(CACHE_DIR, f\"{name}.pkl\")\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading cached model for {name}...\")\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            pipeline = pickle.load(f)\n",
    "    else:\n",
    "        print(f\"Training {name}...\")\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained model\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump(pipeline, f)\n",
    "        \n",
    "        print(f\"Training complete for {name}. Model cached.\")\n",
    "    return name, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached model for GradientBoosting...\n",
      "GradientBoosting\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['bathrooms', 'bedrooms',\n",
      "                                                   'floorAreaSqM',\n",
      "                                                   'livingRooms']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['tenure', 'propertyType',\n",
      "                                                   'currentEnergyRating'])])),\n",
      "                ('model',\n",
      "                 GradientBoostingRegressor(learning_rate=0.05,\n",
      "                                           n_estimators=300))])\n",
      "Loading cached model for RandomForest...\n",
      "RandomForest\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['bathrooms', 'bedrooms',\n",
      "                                                   'floorAreaSqM',\n",
      "                                                   'livingRooms']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['tenure', 'propertyType',\n",
      "                                                   'currentEnergyRating'])])),\n",
      "                ('model',\n",
      "                 RandomForestRegressor(max_depth=10, max_features='sqrt',\n",
      "                                       min_samples_split=5, n_estimators=50,\n",
      "                                       n_jobs=-1))])\n",
      "Loading cached model for Ridge...\n",
      "Ridge\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['bathrooms', 'bedrooms',\n",
      "                                                   'floorAreaSqM',\n",
      "                                                   'livingRooms']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['tenure', 'propertyType',\n",
      "                                                   'currentEnergyRating'])])),\n",
      "                ('model', Ridge(alpha=10))])\n",
      "Training SVR...\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05)),\n",
    "    (\"RandomForest\", RandomForestRegressor(n_estimators=50, min_samples_split=5,\n",
    "                                           max_features='sqrt', max_depth=10, n_jobs=-1)),\n",
    "    (\"Ridge\", Ridge(alpha=10)),\n",
    "    (\"SVR\", SVR(kernel='linear', C=10))\n",
    "]\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models:\n",
    "    best_models = train_model_presets(name, model, preprocessor, best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, X_test, y_test):\n",
    "    with open(f'model_cache/{model_path}', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"🔹 {model} Performance:\")\n",
    "    print(f\"   MAE: {mae:.2f}\")\n",
    "    print(f\"   RMSE: {rmse:.2f}\")\n",
    "    print(f\"   R² Score: {r2:.2f}\\n\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test,\n",
    "                    y=y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min().min(), y_test.max().max()], [y_test.min().min(\n",
    "    ), y_test.max().max()], color='red', linestyle='--')\n",
    "    plt.xlabel(\"True Sale Estimate Price\")\n",
    "    plt.ylabel(\"Predicted Sale Estimate Price\")\n",
    "    plt.title(f\"{model} - True vs. Predicted Prices\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('model_cache'):\n",
    "    evaluate_model(path, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Investigation\n",
    "#### Outcode vs Postcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
