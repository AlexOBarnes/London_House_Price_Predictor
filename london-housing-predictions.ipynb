{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London House Price Predictive Model\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt, timezone as tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kaggle_london_house_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                                   object\n",
       "postcode                                      object\n",
       "country                                       object\n",
       "outcode                                       object\n",
       "latitude                                     float64\n",
       "longitude                                    float64\n",
       "bathrooms                                    float64\n",
       "bedrooms                                     float64\n",
       "floorAreaSqM                                 float64\n",
       "livingRooms                                  float64\n",
       "tenure                                        object\n",
       "propertyType                                  object\n",
       "currentEnergyRating                           object\n",
       "rentEstimate_lowerPrice                      float64\n",
       "rentEstimate_currentPrice                    float64\n",
       "rentEstimate_upperPrice                      float64\n",
       "saleEstimate_lowerPrice                      float64\n",
       "saleEstimate_currentPrice                    float64\n",
       "saleEstimate_upperPrice                      float64\n",
       "saleEstimate_confidenceLevel                  object\n",
       "saleEstimate_ingestedAt                       object\n",
       "saleEstimate_valueChange.numericChange       float64\n",
       "saleEstimate_valueChange.percentageChange    float64\n",
       "saleEstimate_valueChange.saleDate             object\n",
       "history_date                                  object\n",
       "history_price                                  int64\n",
       "history_percentageChange                     float64\n",
       "history_numericChange                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_date'] = pd.to_datetime(df['saleEstimate_ingestedAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_df = df.drop(columns=['history_numericChange', 'history_percentageChange', 'history_date', 'history_price','saleEstimate_valueChange.saleDate','saleEstimate_valueChange.percentageChange','saleEstimate_ingestedAt','saleEstimate_valueChange.numericChange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = key_df[key_df['sale_date'] > dt(2015, 1,1).replace(tzinfo=tz.utc)] #Only considering houses with estimated values in the last 10 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                         0\n",
       "postcode                            0\n",
       "country                             0\n",
       "outcode                             0\n",
       "latitude                            0\n",
       "longitude                           0\n",
       "bathrooms                       77755\n",
       "bedrooms                        40404\n",
       "floorAreaSqM                    25066\n",
       "livingRooms                     60341\n",
       "tenure                          11494\n",
       "propertyType                     1126\n",
       "currentEnergyRating             84288\n",
       "rentEstimate_lowerPrice          1101\n",
       "rentEstimate_currentPrice        1101\n",
       "rentEstimate_upperPrice          1101\n",
       "saleEstimate_lowerPrice             0\n",
       "saleEstimate_currentPrice           0\n",
       "saleEstimate_upperPrice             0\n",
       "saleEstimate_confidenceLevel        0\n",
       "sale_date                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullAddress                         0\n",
       "postcode                            0\n",
       "country                             0\n",
       "outcode                             0\n",
       "latitude                            0\n",
       "longitude                           0\n",
       "bathrooms                           0\n",
       "bedrooms                            0\n",
       "floorAreaSqM                        0\n",
       "livingRooms                         0\n",
       "tenure                           1702\n",
       "propertyType                        0\n",
       "currentEnergyRating             51266\n",
       "rentEstimate_lowerPrice            16\n",
       "rentEstimate_currentPrice          16\n",
       "rentEstimate_upperPrice            16\n",
       "saleEstimate_lowerPrice             0\n",
       "saleEstimate_currentPrice           0\n",
       "saleEstimate_upperPrice             0\n",
       "saleEstimate_confidenceLevel        0\n",
       "sale_date                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = house_df.dropna(subset=['bathrooms', 'livingRooms','bedrooms','floorAreaSqM'])\n",
    "temp_df.isna().sum() # Cannot impute the number of rooms and area of a building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "Leasehold    178804\n",
       "Feudal         2796\n",
       "Freehold       2039\n",
       "Shared          451\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_df = temp_df[temp_df['propertyType'].str.lower().str.contains('flat')]\n",
    "flat_df['tenure'].value_counts() # 98% of flats are leasehold. Would be therefore valid to impute that any flats w/o tenure are in fact leasehold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currentEnergyRating\n",
       "C    69632\n",
       "D    49279\n",
       "B    22602\n",
       "E     9409\n",
       "F      586\n",
       "A      105\n",
       "G      101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_df['currentEnergyRating'].value_counts() #Normally distributed around C/D could impute with preference for B,C,D,E for flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_flat_df = temp_df[~temp_df['propertyType'].str.lower().str.contains('flat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure\n",
       "Freehold     128580\n",
       "Leasehold      4128\n",
       "Feudal           56\n",
       "Shared           22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_flat_df['tenure'].value_counts() #Houses tend to be freehold with 97% of houses Freehold, impute freehold for non flat properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currentEnergyRating\n",
       "D    64439\n",
       "C    32420\n",
       "E    15526\n",
       "B     1714\n",
       "F     1061\n",
       "G      329\n",
       "A      109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_flat_df['currentEnergyRating'].value_counts() #Sharper normal distribution centered around D, could impute with preference for C,D,E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exploration of the data has clear reasoning for imputing some fields and removing rows with missing key fields.\n",
    "- Bathrooms : Cannot be reliably imputed and is necessary for the future model\n",
    "- Living Rooms: Cannot be reliably imputed and is necessary for the future model\n",
    "- Floor Area : Cannot be reliably imputed and is necessary for the future model\n",
    "- Tenure: Can be reliably imputed and is necessary for the future model\n",
    "- Energy rating: Can be reliably imputed and is necessary for the future model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "\n",
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex.Barnes\\AppData\\Local\\Temp\\ipykernel_8940\\2432086349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_df.drop(columns=['rentEstimate_lowerPrice', 'rentEstimate_currentPrice', 'rentEstimate_upperPrice', 'sale_date','saleEstimate_confidenceLevel'],inplace=True)\n",
      "C:\\Users\\Alex.Barnes\\AppData\\Local\\Temp\\ipykernel_8940\\2432086349.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_df['tenure'] = sales_df['propertyType'].apply(lambda x: 'Leasehold' if 'flat' in x.lower() else 'Freehold')\n"
     ]
    }
   ],
   "source": [
    "sales_df = house_df.dropna(subset=['bathrooms', 'livingRooms', 'bedrooms', 'floorAreaSqM']) \n",
    "sales_df.drop(columns=['rentEstimate_lowerPrice', 'rentEstimate_currentPrice', 'rentEstimate_upperPrice', 'sale_date','saleEstimate_confidenceLevel'],inplace=True)\n",
    "sales_df['tenure'] = sales_df['propertyType'].apply(lambda x: 'Leasehold' if 'flat' in x.lower() else 'Freehold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullAddress', 'postcode', 'country', 'outcode', 'latitude',\n",
       "       'longitude', 'bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms',\n",
       "       'tenure', 'propertyType', 'currentEnergyRating',\n",
       "       'saleEstimate_lowerPrice', 'saleEstimate_currentPrice',\n",
       "       'saleEstimate_upperPrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flats = sales_df[sales_df['propertyType'].str.lower().str.contains('flat')]\n",
    "houses = sales_df[~sales_df['propertyType'].str.lower().str.contains('flat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in [flats, houses]:\n",
    "    mean_rating = group['currentEnergyRating'].dropna().astype(str).mode()[0]\n",
    "    std_dev = 1\n",
    "    missing_idx = group['currentEnergyRating'].isna()\n",
    "    group.loc[missing_idx, 'currentEnergyRating'] = np.random.choice(\n",
    "        [mean_rating], size=missing_idx.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([flats, houses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms']\n",
    "categorical_features = ['tenure', 'propertyType', 'currentEnergyRating']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numerical_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"SVR\": SVR(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor()\n",
    "    \n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "        \"Ridge\": {\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        'model__C': [1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__max_depth': [10, 20],\n",
    "        'model__max_features': ['sqrt', 'log2'],\n",
    "        'model__min_samples_split': [5, 10],\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        'model__n_estimators': [100, 300],\n",
    "        'model__learning_rate': [0.05, 0.1]\n",
    "    },\n",
    "    \"HistGradientBoosting\": {\n",
    "        'model__max_iter': [100, 300],\n",
    "        'model__learning_rate': [0.05, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[categorical_features+numerical_features], df['saleEstimate_currentPrice'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name,model,param_grids,preprocessor,best_models):\n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=10,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=5,\n",
    "        n_jobs=10\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for name,model in models.items():\n",
    "    best_models = train_model(name,model,param_grids,preprocessor,best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, title):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"🔹 {title} Performance:\")\n",
    "    print(f\"   MAE: {mae:.2f}\")\n",
    "    print(f\"   RMSE: {rmse:.2f}\")\n",
    "    print(f\"   R² Score: {r2:.2f}\\n\")\n",
    "\n",
    "    # Plot True vs. Predicted\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test['saleEstimate_currentPrice'],\n",
    "                    y=y_pred[:, 1], alpha=0.5)\n",
    "    plt.plot([y_test.min().min(), y_test.max().max()], [y_test.min().min(\n",
    "    ), y_test.max().max()], color='red', linestyle='--')  # Perfect Fit Line\n",
    "    plt.xlabel(\"True Sale Estimate Price\")\n",
    "    plt.ylabel(\"Predicted Sale Estimate Price\")\n",
    "    plt.title(f\"{title} - True vs. Predicted Prices\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in best_models.items():\n",
    "    evaluate_model(model, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Investigation\n",
    "#### Outcode vs Postcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
